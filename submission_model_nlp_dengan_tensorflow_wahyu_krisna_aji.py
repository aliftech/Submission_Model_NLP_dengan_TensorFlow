# -*- coding: utf-8 -*-
"""Submission_Model_NLP_dengan_TensorFlow_Wahyu_krisna_Aji.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19J9ie9HcgLsyvcz0vJDZmwk1A_o9LbVM

*   Nama : Wahyu Krisna Aji
*   Dataset : kaggle_movie_train.csv
*   Sumber : Kaggle
*   Link Dataset : https://www.kaggle.com/lokkagle/movie-genre-datamovie-genre-data
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential

class modelCallbacks(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.9):
      print("Expected accuracy have been achieved")
      self.model.stop_training = True
cb = modelCallbacks()

data = pd.read_csv('kaggle_movie_train.csv', sep = ',')
data.tail()

data['genre'].value_counts()

data = data.drop(columns=[
    'id'])

data.head()

data = data[~data['genre'].isin(['sci-fi','horror','other','adventure','romance'])]
data['genre'].value_counts()

genre = pd.get_dummies(data['genre'])
data_baru = pd.concat([data, genre], axis=1)
data_baru = data_baru.drop(columns='genre')
data_baru

data_baru.columns

# tentang_film = data_baru['about'].str.lower()
tentang_film = data_baru['text'].astype(str)
genre_film = data_baru[[
       'action', 'comedy', 'drama', 'thriller']].values

tentang_latih, tentang_test, genre_latih, genre_test = train_test_split(tentang_film, genre_film, test_size=0.2)

tokenizer = Tokenizer(num_words=5000, oov_token='*')
tokenizer.fit_on_texts(tentang_latih) 
tokenizer.fit_on_texts(tentang_test)
 
sekuens_latih = tokenizer.texts_to_sequences(tentang_latih)
sekuens_test = tokenizer.texts_to_sequences(tentang_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

model = Sequential([
    Embedding(input_dim=5000, output_dim=16),
    LSTM(64),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])
Adam(learning_rate=0.00146, name='Adam')
model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

model.summary()

model_history = model.fit(
    padded_latih, 
    genre_latih, 
    epochs=50, 
    validation_data=(padded_test, genre_test), 
    verbose=2,
    batch_size=128,
    callbacks=[cb]
  )

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()